{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 案例分析一：Kaggle Competition | Titanic Machine Learning from Disaster\n",
    "\n",
    "\n",
    "***本作基于： [Titanic](https://github.com/agconti/kaggle-titanic). 原数据来源： [Kaggle.com](http://www.kaggle.com/c/titanic-gettingStarted).***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `import … as …`是给我们引入的包加上缩写，在后续调用的时候可以直接用缩写调用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"train.csv\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "df #直接打变量名字就可以预览数据内容"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "df = df.drop(['Ticket','Cabin'], axis=1)\n",
    "df = df.dropna() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `.drop()`是用于删除整一列数据，不作额外判断。  \n",
    "* 如果将`axis`参数改为1 (默认为0)，则会沿纵向删除数据  \n",
    "#### `.dropna()`用于删除空值NaN  \n",
    "* 在不额外调整`axis`参数值时，同样默认遍历全部行进行删除"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 案例分析二： Data Cleaning with NumPy and Pandas\n",
    "  \n",
    "***本作基于： [Data-cleaning](https://github.com/mramshaw/Data-Cleaning). 原数据来源： [Pandas and NumPy](https://realpython.com/python-data-cleaning-numpy-pandas/).***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('BL-Flickr-Images-Book.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `df.head()`意为预览前五列数据\n",
    "* 括号中定义数字可以预览更多行的数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_drop = ['Edition Statement',\n",
    "          'Corporate Author',\n",
    "          'Corporate Contributors',\n",
    "          'Former owner',\n",
    "          'Engraver',\n",
    "          'Contributors',\n",
    "          'Issuance type',\n",
    "          'Shelfmarks']\n",
    "df.drop(to_drop, inplace=True, axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `df.drop(labels= ，inplace=false，axis=0，errors='raise')`是drop函数的部分语法默认值\n",
    "* labels：在这里用`to_drop`统一标注想要删除的列；在较小的数据集中，可以直接用字符串标明需要删除的列名\n",
    "* axis：默认值为0，按纵向删除；在此改为1，按列方向删除\n",
    "* inplace：默认值为`false`；如果将参数改为`True`，将会直接覆盖原数据，操作不可逆\n",
    "* errors：默认值为`'raise'`，此时如果出现不存在的列名则返回`KeyError`；参数改为'ignore'便可以忽略打错的列名"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Identifier'].is_unique"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `df['Identifier'].is_unique` 是测试某列名是否是唯一的，因为我们想要把在后续以这个列名为基础查看数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.set_index('Identifier')\n",
    "# df.set_index('Identifier', inplace=True) 效果一样\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `df.set_index('Identifier')` 是将检索值固定为了我们想要的，替换掉了默认的0,1,2…"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[216]\n",
    "# df.iloc[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `df.loc[]` 是查询特定的检索值所在行的数据，在这里是Identifier的编号\n",
    "* 如果loc[]查找的数值不在范围内，会返回'KeyError'\n",
    "#### `df.iloc[]` 是查询相对的检索值所在的数据，默认值是`0`，即第一行的数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.get_dtype_counts()--》老版\n",
    "df.dtypes.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `df.dtypes.value_counts()` 是查询数据中存在的数据类型\n",
    "* object：是主要关注的结果\n",
    "* Name：在这句代码中基本上可以忽略\n",
    "* dtype：指的是这句代码统计结果的储存方式是整数->在计算比例的时候可能统计结果会出现float64的情况"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[1905:, 'Date of Publication'].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "通过这样检索“发行日期”的数据，发现格式不是统一的"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regex = r'^(\\d{4})'\n",
    "extr = df['Date of Publication'].str.extract(r'^(\\d{4})', expand=False)\n",
    "extr.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `r'^(\\d{4})'` 是严格匹配字符串前四位数字的正则表达式\n",
    "* `r' '`表示原始字符串，避免`\\d`被python误识别\n",
    "* `^`:是匹配字符串的起始符\n",
    "* `\\d`：意为匹配任意数字（依赖后续条件）\n",
    "* `{n}`：意为匹配前一个字符n次\n",
    "* `（）`：将匹配的内容捕捉为一个分组，用于后续提取  \n",
    "由于正则表达式，笔者仍掌握不太熟练，其他语法元素可以参考: ***[CDSN论坛](https://blog.csdn.net/weixin_42448623/article/details/102785880)***\n",
    "#### `.str.extract(r'^(\\d{4})', expand=False)`用于从正则表达式中提取匹配的内容\n",
    "* 在正则表达式位置，可以用提前定义好的变量名，在这里可以用`rf^{regex}`来替换原本表达式的参数位置\n",
    "* expand：默认值为`True`，在匹配完数据后返回原数据+匹配后的数据；改为`False`后只返回匹配后的数据，匹配失败的返回`NaN`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Date of Publication'] = pd.to_numeric(extr,errors='coerce')\n",
    "df['Date of Publication'].dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `pd.to_numeric()` 是将目标数据强制转换为数值类型（比如原来是字符串）\n",
    "* `error`：设定参数为`coerce`可以将无效值转换为`NaN`；`ignore`可以保留原始数据类型，但是不建议\n",
    "* 如果全部值都可以转换为整数，则`.dtype`结果会返回`int64`；如果存在NaN，那么会转换为`float64`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Date of Publication'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "至此，我们格式化了出版日期的年份。接下来开始格式化出版地名的数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Place of Publication'].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pub = df['Place of Publication']\n",
    "london = pub.str.contains('London')\n",
    "london[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `str.contains()` 是用于检查字符串列是否包含特定子串（可以是正则表达式）\n",
    "* pat：要匹配的是字符串还是正则表达式\n",
    "* case：默认为`True`，意为是否区分大小写\n",
    "* flags：正则表达式的标志（如忽略大小写）\n",
    "* na：处理缺失值的方式，默认将`NaN`处理为`False`\n",
    "* regex：默认为`True`，即视为正则表达式；在这里因为无需匹配额外的符号等，所以用True和False没有区别\n",
    "  \n",
    "在这里结果是：精确匹配是否存在字符串为`\"London\"`  \n",
    "如果改为`.str.contains('London', case=False)`，则可以查到登记为`\"london\"`的出版地\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oxford = pub.str.contains('Oxford')\n",
    "df['Place of Publication'] = np.where(london, 'London',\n",
    "                                      np.where(oxford, 'Oxford',\n",
    "                                      pub.str.replace('-', ' ')))\n",
    "df['Place of Publication'].head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `np.where()` 是为了满足：根据不同条件返回不同的值\n",
    "* 参数填充顺序为：  \n",
    "      i.条件1，满足条件时的填充值；  \n",
    "      ii.用嵌套自身的方式填充：条件2，满足条件2时填充的值  \n",
    "      iii.在嵌套的最末尾填上如果不满足时，需要填充的值\n",
    "  \n",
    "* 此处的判断逻辑为：\n",
    "      i.检查在检索的列中，是否存在`London`，满足的话填充\"London\"  \n",
    "      ii.如果没有`London`，转入第二层，检查是否存在`Oxford`，满足的话填充\"Oxford\"  \n",
    "      iii.如果都不满足，便仅将\"-\"替换为\"空格\"  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "至此，我们就完成了对出版日期和出版地的数据清洗。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 案例分析三： NYC taxi Data Cleaning  \n",
    "\n",
    "***原数据来源： [NYC Taxi](https://www.nyc.gov/site/tlc/about/tlc-trip-record-data.page).***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install pyarrow\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "df = pd.read_csv(\"C:\\\\Users\\\\Kris\\\\Github类_自用\\\\dataset\\\\Case 3\\\\yellow_tripdata_2014-01.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10501946"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['vendor_id', ' pickup_datetime', ' dropoff_datetime',\n",
      "       ' passenger_count', ' trip_distance', ' pickup_longitude',\n",
      "       ' pickup_latitude', ' rate_code', ' store_and_fwd_flag',\n",
      "       ' dropoff_longitude', ' dropoff_latitude', ' payment_type',\n",
      "       ' fare_amount', ' surcharge', ' mta_tax', ' tip_amount',\n",
      "       ' tolls_amount', ' total_amount'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[(df[' passenger_count'].between(0,4))]\n",
    "# df = [(df[' passenger_count'] >= 0) & (df[' passenger_count'] <= 4)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `df = df[(df[' '].between())]` 是用于筛出特定标签的特定数据范围-在这里用于筛除异常值\n",
    "* 用`.between`会比用大于等于或者小于等于更简洁\n",
    "* 记住不能使用方括号，使用`.between`方法已经是闭区间\n",
    "* 注：纽约的出租车不一定只能载四个人，在这里仅作练习目的"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10501946"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `df.shape[0]` 是用于筛出特定标签的特定数据范围-在这里用于筛除异常值\n",
    "* 作为属性，而非方法，不用括号调用\n",
    "* 如果不加`[0]`，能够返回行和列的信息，这里仅需要了解删除了多少数据\n",
    "* 等价于`len(df)`\n",
    "* 区别于：`df.size`，这个属性会输出全部的元素数量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = df.drop(['vendor_id',' pickup_datetime', ' dropoff_datetime',\n",
    "#               ' passenger_count',' rate_code', ' store_and_fwd_flag',\n",
    "#               ' payment_type',' fare_amount', ' surcharge',\n",
    "#               ' mta_tax',' tip_amount',' tolls_amount'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>trip_distance</th>\n",
       "      <th>pickup_longitude</th>\n",
       "      <th>pickup_latitude</th>\n",
       "      <th>dropoff_longitude</th>\n",
       "      <th>dropoff_latitude</th>\n",
       "      <th>total_amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.7</td>\n",
       "      <td>-73.994770</td>\n",
       "      <td>40.736828</td>\n",
       "      <td>-73.982227</td>\n",
       "      <td>40.731790</td>\n",
       "      <td>8.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.4</td>\n",
       "      <td>-73.982392</td>\n",
       "      <td>40.773382</td>\n",
       "      <td>-73.960449</td>\n",
       "      <td>40.763995</td>\n",
       "      <td>11.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.3</td>\n",
       "      <td>-73.988570</td>\n",
       "      <td>40.739406</td>\n",
       "      <td>-73.986626</td>\n",
       "      <td>40.765217</td>\n",
       "      <td>14.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.7</td>\n",
       "      <td>-73.960213</td>\n",
       "      <td>40.770464</td>\n",
       "      <td>-73.979863</td>\n",
       "      <td>40.777050</td>\n",
       "      <td>10.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.9</td>\n",
       "      <td>-73.995371</td>\n",
       "      <td>40.717248</td>\n",
       "      <td>-73.984367</td>\n",
       "      <td>40.720524</td>\n",
       "      <td>8.75</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   trip_distance  pickup_longitude  pickup_latitude  dropoff_longitude  \\\n",
       "0            0.7        -73.994770        40.736828         -73.982227   \n",
       "1            1.4        -73.982392        40.773382         -73.960449   \n",
       "2            2.3        -73.988570        40.739406         -73.986626   \n",
       "3            1.7        -73.960213        40.770464         -73.979863   \n",
       "4            0.9        -73.995371        40.717248         -73.984367   \n",
       "\n",
       "   dropoff_latitude  total_amount  \n",
       "0         40.731790          8.90  \n",
       "1         40.763995         11.40  \n",
       "2         40.765217         14.00  \n",
       "3         40.777050         10.20  \n",
       "4         40.720524          8.75  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
